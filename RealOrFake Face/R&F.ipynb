{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1579fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cc14939",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs=20\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9791eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = r\"/Users/rituraj/Desktop/Internship/RealOrFake Face/dataset\"\n",
    "categories = [\"fake\",\"real\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e3b97bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "labels=[]\n",
    "for category in categories:\n",
    "    path = os.path.join(directory, category)\n",
    "    for img in os.listdir(path):\n",
    "        img_path = os.path.join(path, img)\n",
    "        image = load_img(img_path, target_size=(224, 224))\n",
    "        image = img_to_array(image)\n",
    "        image = preprocess_input(image)\n",
    "\n",
    "        data.append(image)\n",
    "        labels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32408194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ONE HOT ENCODING ON LABELS\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638d2d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data,dtype='float32')\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7618e2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.20,stratify=labels , random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87dc8243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMAGE DATA CLASS FOR IMAGE AUGMENTATION\n",
    "augm = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9909d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 01:09:12.603067: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-21 01:09:12.603977: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "#MOBILENETS MODEL\n",
    "baseM = MobileNetV2(weights=\"imagenet\", include_top=False,\n",
    "    input_tensor=Input(shape=(224, 224, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4878e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL Head\n",
    "finalM = baseM.output\n",
    "finalM = AveragePooling2D(pool_size=(7, 7))(finalM)\n",
    "finalM = Flatten(name=\"flatten\")(finalM)\n",
    "finalM = Dense(128, activation=\"relu\")(finalM)\n",
    "finalM = Dropout(0.5)(finalM)\n",
    "finalM = Dense(2, activation=\"softmax\")(finalM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be640d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL MODEL\n",
    "model = Model(inputs=baseM.input,outputs=finalM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80c2a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in baseM.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c71f588",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling Model\n",
    "opt = Adam(learning_rate=learning_rate, decay=learning_rate / epochs)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315b19ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 01:09:14.477329: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 01:09:15.791528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - ETA: 0s - loss: 0.7727 - accuracy: 0.5214"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-21 01:09:30.917594: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 20s 342ms/step - loss: 0.7727 - accuracy: 0.5214 - val_loss: 0.6843 - val_accuracy: 0.5703\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 16s 321ms/step - loss: 0.7116 - accuracy: 0.5656 - val_loss: 0.6637 - val_accuracy: 0.5990\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 16s 324ms/step - loss: 0.6874 - accuracy: 0.5962 - val_loss: 0.6475 - val_accuracy: 0.6458\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 17s 332ms/step - loss: 0.6628 - accuracy: 0.6183 - val_loss: 0.6342 - val_accuracy: 0.6458\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 17s 344ms/step - loss: 0.6500 - accuracy: 0.6311 - val_loss: 0.6270 - val_accuracy: 0.6797\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 17s 341ms/step - loss: 0.6466 - accuracy: 0.6366 - val_loss: 0.6174 - val_accuracy: 0.7031\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 17s 339ms/step - loss: 0.6281 - accuracy: 0.6538 - val_loss: 0.6026 - val_accuracy: 0.6693\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 17s 326ms/step - loss: 0.6223 - accuracy: 0.6612 - val_loss: 0.5974 - val_accuracy: 0.6953\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 17s 329ms/step - loss: 0.6153 - accuracy: 0.6734 - val_loss: 0.5876 - val_accuracy: 0.6979\n",
      "Epoch 10/20\n",
      "25/51 [=============>................] - ETA: 7s - loss: 0.5953 - accuracy: 0.6812"
     ]
    }
   ],
   "source": [
    "output = model.fit(X_train,y_train,batch_size=batch_size,\n",
    "                  steps_per_epoch=len(X_train)//batch_size,\n",
    "                  validation_data=(X_train,y_train),\n",
    "                  validation_steps=len(X_test)//batch_size,\n",
    "                  epochs = epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910611f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test,batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4092ab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_l = np.argmax(predict,axis=1)\n",
    "print(classification_report(y_test.argmax(axis=1),predict_l,target_names = lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e75acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = epochs\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), output.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), output.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), output.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), output.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f85807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single Prediction\n",
    "image = load_img('testing/t4r.jpg', target_size=(224, 224))\n",
    "image = img_to_array(image)\n",
    "image = preprocess_input(image)\n",
    "sdf = []\n",
    "sdf.append(image)\n",
    "sdf = np.array(sdf,dtype='float32')\n",
    "\n",
    "single_prediction = model.predict(sdf)\n",
    "predict_t = np.argmax(single_prediction,axis=1)\n",
    "answer = lb.inverse_transform(predict_t)\n",
    "\n",
    "if answer=='fake':\n",
    "    print('Fake')\n",
    "else:\n",
    "    print('Real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bdd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"RealOrFakeFaceModel.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170548fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "905c3e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae8507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7102b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
